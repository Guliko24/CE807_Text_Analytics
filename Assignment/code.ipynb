{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guliko24/CE807_Text_Analytics/blob/main/Assignment/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student ID: 2323017\n",
        "\n",
        "**You student_id is your 7/8 digit faser number.**\n",
        "\n",
        "This is a sample format for CE807: Assignment . You must follow the format.\n",
        "The code will have three broad sections, and additional section, if needed,\n",
        "\n",
        "\n",
        "1.   Common Codes\n",
        "2.   Method/model 1 Specific Codes\n",
        "3.   Method/model 2 Specific Codes\n",
        "4.   Other Method/model Codes, if any\n",
        "\n",
        "**You must have `train_unsup`, `test_unsup` for Unsupervised method  and `train_dis`, `test_dis` for Discriminatuve method to perform full training and testing. This will be evaluated automatically, without this your code will fail and no marked.**\n",
        "\n",
        "You code should be proverly indended, print as much as possible, follow standard coding (https://peps.python.org/pep-0008/) and documentaion (https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.01-Help-And-Documentation.ipynb) practices.\n",
        "\n",
        "Before each `code block/function`, you must have a `text block` which explain what code block/function is going to do. For each function/class, you need to properly document what are it's input, functionality and output.\n",
        "\n",
        "If you are using any non-standard library, you must have command to install that, for example `pip install datasets`.\n",
        "\n",
        "You must print `train`, `validation` and `test` performance measures.\n",
        "\n",
        "You must also print `train` and `validation` loss in each `epoch`, wherever you are using `epoch`, say in any deep learning algorithms.\n",
        "\n",
        "Your code must\n",
        "\n",
        "*   To reproducibality of the results you must use a `seed`, you have to set seed in `torch`, `numpy` etc, use same seed everywhere **and your Student ID should be your seed**.\n",
        "*   read dataset from './data/number/', where number is last digit of your student_id folder which will have 3 files [`train.csv`, `val.csv`, `test.csv`]\n",
        "*   save model after finishing the training in './model/student_id/Model_Unsup/' and './model/student_id/Model_Dis/' for Unsupervised and Discriminative model respectively.\n",
        "*   at testing time you will load models from './model/student_id/Model_Unsup/' and './model/student_id/Model_Dis/'  for Unsupervised and Discriminative model respectively. Your output file based on the test file will be named ‚Äútest.csv‚Äù and you will add/modify ‚Äúout_label_model_unsup‚Äù and ‚Äúout_label_model_dis‚Äù column in the existing columns from test.csv. These outputs will be generated from your trained models.\n",
        "*  after testing, your output file will be named ‚Äútest.csv‚Äù and you will add/modify ‚Äúout_label_model_unsup‚Äù and ‚Äúout_label_model_Dis‚Äù column in the existing columns from test.csv. These outputs will be generated from your trained models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Install and import all required libraries first before starting to code.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VgzEm1gDYBUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install all require libraries. For example, `transformers`"
      ],
      "metadata": {
        "id": "_3ZWJlO6JOqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "81A_4_dKJV4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9314bd83-8775-40b4-d540-ee9cacd9fd85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import all require libraries.\n",
        "For example, `numpy`"
      ],
      "metadata": {
        "id": "U5XEt6asIi3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "TKEZRYhIImbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's put your student id as a variable, that you will use different places**"
      ],
      "metadata": {
        "id": "pd5kSsAPZoE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_id = 2323017 # Note this is an interger and you need to input your id"
      ],
      "metadata": {
        "id": "rqP6pp_3ZkVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set `seed` for all libraries like `torch`, `numpy` etc as my student id"
      ],
      "metadata": {
        "id": "RiLUrQ-3zC6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set same seeds for all libraries\n",
        "\n",
        "#numpy seed\n",
        "np.random.seed(student_id)"
      ],
      "metadata": {
        "id": "TYUn2tj3zCFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common Codes\n",
        "\n",
        "In this section you will write all common codes, for examples\n",
        "\n",
        "\n",
        "*   Data read\n",
        "*   Command Line argument reading\n",
        "*   Performance Matrics\n",
        "*   Print Dataset Statistics\n",
        "*   Saving model and output\n",
        "*   Loading Model and output\n",
        "*   etc\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dlj_VQrkbLgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's first allow the GDrive access and set data and model paths**\n",
        "\n",
        "For examples,\n",
        "\n",
        "student_id = 2323017\n",
        "\n",
        "set GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = ‚Äò./CE807-24-SU/Lab09/‚Äô in your GDrive\n",
        "\n",
        "now set all global variable,\n",
        "\n",
        "\n",
        "Sample output directory and file structure: https://drive.google.com/drive/folders/1ZCVOBjsxu3bnXRk8tUVkL97Bm1MmS_gE?usp=sharing   "
      ],
      "metadata": {
        "id": "uOESFmIPn_nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "L1kvIe1NbDoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0b4c19-4e5c-45b1-df2d-e2cc464ab30e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the file\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = './CE807-24-SU//Lab09/'\n",
        "GOOGLE_DRIVE_PATH = os.path.join('gdrive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))"
      ],
      "metadata": {
        "id": "8_vXkfWmi9mA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad17c61e-8c96-4dde-b52f-4472fed5348a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data', 'model', 'code.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Let's do some exploratory data analysis and pre-processing using SpaCy**"
      ],
      "metadata": {
        "id": "jZ2VE0swBVc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import spacy\n",
        "import spacy\n",
        "\n",
        "#Install spaCy\n",
        "!pip install spacy\n",
        "\n",
        "#Download the English langugage model for spaCy\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "#Load the English model\n",
        "nlp = spacy.load(\"en_core_web_sm\") #Here, spacy.load, loads the English model and assigns it to variable nlp\n",
        "\n",
        "#When you execute nlp = spacy.load('en'), spaCy downloads and loads the pre-trained English language model\n",
        "#into memory and assigns it to the variable nlp.\n",
        "#This pre-trained model contains information about word vectors, part-of-speech tags, syntactic dependencies, and other lin"
      ],
      "metadata": {
        "id": "Owf3RonrBgtK",
        "outputId": "79bb8141-6bcf-4525-9f29-af1a087b4dfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's do explorative data analysis and pre-processing using availabe packages such as SpaCy\n",
        "\n",
        "\n",
        "file_path = '/content/gdrive/MyDrive/CE807-24-SU/Lab09/data/37/train.csv'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    sentiment_texts = file.readlines()\n",
        "\n",
        "# After this block of code executes, the 'sentiment_texts' list contains\n",
        "# all the lines of text read from the 'sentiment_examples.txt' file.\n",
        "# The 'with' statement is used to open the file in a way that ensures it is automatically closed after the block of code inside the 'with' statement is executed.\n",
        "# 'open(file_path, 'r', encoding='utf-8')' opens the file in read mode ('r') with UTF-8 encoding ('utf-8').\n",
        "# 'as file' assigns the opened file object to the variable 'file', which can be used to read from the file.\n",
        "# 'file.readlines()' reads all lines from the file and returns a list of strings, where each string corresponds to a line of text in the file.\n",
        "# These strings are stored in the 'sentiment_texts' list for further processing."
      ],
      "metadata": {
        "id": "6c4BIiM7A2CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty lists to store the results\n",
        "token_lists = []  # List to store tokens for each sentiment example\n",
        "filtered_token_lists = []  # List to store filtered tokens (after stop word removal) for each sentiment example\n",
        "pos_tag_lists = []  # List to store POS tags for each sentiment example\n",
        "ner_lists = []  # List to store named entities for each sentiment example\n",
        "\n",
        "# Process each sentiment example using spaCy and store the results\n",
        "for sentiment_text in sentiment_texts:\n",
        "    doc = nlp(sentiment_text.strip())  # Strip any leading/trailing whitespace\n",
        "    #The .strip() method is used to clean up the sentiment_text\n",
        "    #before passing it to the spaCy nlp pipeline for processing.\n",
        "    #This ensures that there are no unwanted spaces or newline characters\n",
        "    #that could affect the processing of the text by spaCy.\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = [token.text for token in doc]  # Extract tokens from the processed text\n",
        "    token_lists.append(tokens)  # Append tokens list to token_lists\n",
        "    #Creates a list of tokens and appending it to the token_lists list.\n",
        "    #This is done to store the tokens for each sentiment example.\n",
        "\n",
        "    # Stop Word Removal filter\n",
        "    filtered_tokens = [token.text for token in doc if not token.is_stop]  # Filter out stop words\n",
        "    filtered_token_lists.append(filtered_tokens)  # Append filtered tokens list to filtered_token_lists\n",
        "\n",
        "\n",
        "    # Part-of-Speech Tagging (POS tagging)\n",
        "    pos_tags = [(token.text, token.pos_) for token in doc]  # Extract token text and POS tags\n",
        "    pos_tag_lists.append(pos_tags)  # Append POS tags list to pos_tag_lists\n",
        "\n",
        "    # Named Entity Recognition (NER)\n",
        "    ner_entities = [(ent.text, ent.label_) for ent in doc.ents]  # Extract named entities and their labels\n",
        "    ner_lists.append(ner_entities)  # Append named entities list to ner_lists\n",
        "\n",
        "# Create a DataFrame to organize the results\n",
        "results_df = pd.DataFrame({\n",
        "    'Sentiment Example': sentiment_texts,\n",
        "    'Tokens': token_lists,\n",
        "    'Filtered Tokens': filtered_token_lists,\n",
        "    'POS Tags': pos_tag_lists,\n",
        "    'Named Entities': ner_lists\n",
        "})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(results_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "tyLnTVzL_EZv",
        "outputId": "28086cd6-ca28-47df-be4a-ffce418dbe23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Sentiment Example  \\\n",
            "0                                      sentiment,text\\n   \n",
            "1                                positive,Works great\\n   \n",
            "2     negative,I drive an SUV and these do not fit o...   \n",
            "3            positive,It does what is supposed to be.\\n   \n",
            "4     positive,I use this on my 2006 bmw m5.  works ...   \n",
            "...                                                 ...   \n",
            "3677  positive,Really good quality dog bone. Heavy d...   \n",
            "3678                                positive,snug fit\\n   \n",
            "3679  negative,It was so bad I sent it back .I bough...   \n",
            "3680  positive,\"Perfect fit in my 4 door, 4wd 1998 T...   \n",
            "3681             positive,fits fine.  Easy to install\\n   \n",
            "\n",
            "                                                 Tokens  \\\n",
            "0                                  [sentiment, ,, text]   \n",
            "1                           [positive, ,, Works, great]   \n",
            "2     [negative, ,, I, drive, an, SUV, and, these, d...   \n",
            "3     [positive, ,, It, does, what, is, supposed, to...   \n",
            "4     [positive, ,, I, use, this, on, my, 2006, bmw,...   \n",
            "...                                                 ...   \n",
            "3677  [positive, ,, Really, good, quality, dog, bone...   \n",
            "3678                           [positive, ,, snug, fit]   \n",
            "3679  [negative, ,, It, was, so, bad, I, sent, it, b...   \n",
            "3680  [positive,\"Perfect, fit, in, my, 4, door, ,, 4...   \n",
            "3681  [positive, ,, fits, fine, .,  , Easy, to, inst...   \n",
            "\n",
            "                                        Filtered Tokens  \\\n",
            "0                                  [sentiment, ,, text]   \n",
            "1                           [positive, ,, Works, great]   \n",
            "2           [negative, ,, drive, SUV, fit, seat, .., üòû]   \n",
            "3                            [positive, ,, supposed, .]   \n",
            "4     [positive, ,, use, 2006, bmw, m5, .,  , works,...   \n",
            "...                                                 ...   \n",
            "3677  [positive, ,, good, quality, dog, bone, ., Hea...   \n",
            "3678                           [positive, ,, snug, fit]   \n",
            "3679  [negative, ,, bad, sent, .I, bought, new, prod...   \n",
            "3680  [positive,\"Perfect, fit, 4, door, ,, 4wd, 1998...   \n",
            "3681     [positive, ,, fits, fine, .,  , Easy, install]   \n",
            "\n",
            "                                               POS Tags  \\\n",
            "0         [(sentiment, NOUN), (,, PUNCT), (text, NOUN)]   \n",
            "1     [(positive, ADJ), (,, PUNCT), (Works, VERB), (...   \n",
            "2     [(negative, ADJ), (,, PUNCT), (I, PRON), (driv...   \n",
            "3     [(positive, ADJ), (,, PUNCT), (It, PRON), (doe...   \n",
            "4     [(positive, ADJ), (,, PUNCT), (I, PRON), (use,...   \n",
            "...                                                 ...   \n",
            "3677  [(positive, ADJ), (,, PUNCT), (Really, ADV), (...   \n",
            "3678  [(positive, ADJ), (,, PUNCT), (snug, PROPN), (...   \n",
            "3679  [(negative, ADJ), (,, PUNCT), (It, PRON), (was...   \n",
            "3680  [(positive,\"Perfect, NOUN), (fit, ADJ), (in, A...   \n",
            "3681  [(positive, ADJ), (,, PUNCT), (fits, VERB), (f...   \n",
            "\n",
            "                                         Named Entities  \n",
            "0                                                    []  \n",
            "1                                     [(Works, PERSON)]  \n",
            "2                                                    []  \n",
            "3                                                    []  \n",
            "4                                        [(2006, DATE)]  \n",
            "...                                                 ...  \n",
            "3677                                                 []  \n",
            "3678                                                 []  \n",
            "3679                                                 []  \n",
            "3680  [(4, CARDINAL), (4wd 1998, ORG), (about 5 minu...  \n",
            "3681                                                 []  \n",
            "\n",
            "[3682 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the DataFrame to a CSV file named 'processed_data.csv' without including the index\n",
        "results_df.to_csv('processed_data.csv', index=False)\n",
        "\n",
        "# Read the CSV file 'processed_data.csv' into a Pandas DataFrame called processed_df\n",
        "# Specify the encoding as 'latin-1' to handle special characters if present\n",
        "processed_df = pd.read_csv('/content/processed_data.csv', encoding='latin-1')"
      ],
      "metadata": {
        "id": "DyANzuGtDnrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df.head()"
      ],
      "metadata": {
        "id": "sDmUvsjiD2Ek",
        "outputId": "e38e9ed3-274a-46ea-dc3c-82be4d36efb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Sentiment Example  \\\n",
              "0                                   sentiment,text\\n   \n",
              "1                             positive,Works great\\n   \n",
              "2  negative,I drive an SUV and these do not fit o...   \n",
              "3         positive,It does what is supposed to be.\\n   \n",
              "4  positive,I use this on my 2006 bmw m5.  works ...   \n",
              "\n",
              "                                              Tokens  \\\n",
              "0                         ['sentiment', ',', 'text']   \n",
              "1                ['positive', ',', 'Works', 'great']   \n",
              "2  ['negative', ',', 'I', 'drive', 'an', 'SUV', '...   \n",
              "3  ['positive', ',', 'It', 'does', 'what', 'is', ...   \n",
              "4  ['positive', ',', 'I', 'use', 'this', 'on', 'm...   \n",
              "\n",
              "                                     Filtered Tokens  \\\n",
              "0                         ['sentiment', ',', 'text']   \n",
              "1                ['positive', ',', 'Works', 'great']   \n",
              "2  ['negative', ',', 'drive', 'SUV', 'fit', 'seat...   \n",
              "3                 ['positive', ',', 'supposed', '.']   \n",
              "4  ['positive', ',', 'use', '2006', 'bmw', 'm5', ...   \n",
              "\n",
              "                                            POS Tags         Named Entities  \n",
              "0  [('sentiment', 'NOUN'), (',', 'PUNCT'), ('text...                     []  \n",
              "1  [('positive', 'ADJ'), (',', 'PUNCT'), ('Works'...  [('Works', 'PERSON')]  \n",
              "2  [('negative', 'ADJ'), (',', 'PUNCT'), ('I', 'P...                     []  \n",
              "3  [('positive', 'ADJ'), (',', 'PUNCT'), ('It', '...                     []  \n",
              "4  [('positive', 'ADJ'), (',', 'PUNCT'), ('I', 'P...     [('2006', 'DATE')]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-943c2c24-d3c7-49b6-8e20-30b4bc1e632c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment Example</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Filtered Tokens</th>\n",
              "      <th>POS Tags</th>\n",
              "      <th>Named Entities</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sentiment,text\\n</td>\n",
              "      <td>['sentiment', ',', 'text']</td>\n",
              "      <td>['sentiment', ',', 'text']</td>\n",
              "      <td>[('sentiment', 'NOUN'), (',', 'PUNCT'), ('text...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive,Works great\\n</td>\n",
              "      <td>['positive', ',', 'Works', 'great']</td>\n",
              "      <td>['positive', ',', 'Works', 'great']</td>\n",
              "      <td>[('positive', 'ADJ'), (',', 'PUNCT'), ('Works'...</td>\n",
              "      <td>[('Works', 'PERSON')]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative,I drive an SUV and these do not fit o...</td>\n",
              "      <td>['negative', ',', 'I', 'drive', 'an', 'SUV', '...</td>\n",
              "      <td>['negative', ',', 'drive', 'SUV', 'fit', 'seat...</td>\n",
              "      <td>[('negative', 'ADJ'), (',', 'PUNCT'), ('I', 'P...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive,It does what is supposed to be.\\n</td>\n",
              "      <td>['positive', ',', 'It', 'does', 'what', 'is', ...</td>\n",
              "      <td>['positive', ',', 'supposed', '.']</td>\n",
              "      <td>[('positive', 'ADJ'), (',', 'PUNCT'), ('It', '...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive,I use this on my 2006 bmw m5.  works ...</td>\n",
              "      <td>['positive', ',', 'I', 'use', 'this', 'on', 'm...</td>\n",
              "      <td>['positive', ',', 'use', '2006', 'bmw', 'm5', ...</td>\n",
              "      <td>[('positive', 'ADJ'), (',', 'PUNCT'), ('I', 'P...</td>\n",
              "      <td>[('2006', 'DATE')]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-943c2c24-d3c7-49b6-8e20-30b4bc1e632c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-943c2c24-d3c7-49b6-8e20-30b4bc1e632c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-943c2c24-d3c7-49b6-8e20-30b4bc1e632c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-75ec4e09-7984-4cd7-a1bd-c55a5d881bca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75ec4e09-7984-4cd7-a1bd-c55a5d881bca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-75ec4e09-7984-4cd7-a1bd-c55a5d881bca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "processed_df",
              "summary": "{\n  \"name\": \"processed_df\",\n  \"rows\": 3682,\n  \"fields\": [\n    {\n      \"column\": \"Sentiment Example\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3550,\n        \"samples\": [\n          \"positive,\\\"This helmet fits like it should, unlike some of the MAJOR well known brands. I have mine stickered up, and it draws attention. Would, and will, buy this helmet model again (new color). The ONLY thing I don't like, the strap fitting arrangement.\\\"\\n\",\n          \"positive,\\\"does as its supposed to, as it has for me for the last 30 years!!!\\\"\\n\",\n          \"negative,\\\"The cover its self is good but the cable that holds it on sucks, wind blows and the front or back depending on wind direction, blows up an just flops in the wind and rain or whatever its doing. needs a cable or something that goes front to back.\\\"\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3548,\n        \"samples\": [\n          \"['positive,\\\"This', 'helmet', 'fits', 'like', 'it', 'should', ',', 'unlike', 'some', 'of', 'the', 'MAJOR', 'well', 'known', 'brands', '.', 'I', 'have', 'mine', 'stickered', 'up', ',', 'and', 'it', 'draws', 'attention', '.', 'Would', ',', 'and', 'will', ',', 'buy', 'this', 'helmet', 'model', 'again', '(', 'new', 'color', ')', '.', 'The', 'ONLY', 'thing', 'I', 'do', \\\"n't\\\", 'like', ',', 'the', 'strap', 'fitting', 'arrangement', '.', '\\\"']\",\n          \"['negative,\\\"Not', 'what', 'I', 'expected', ',', 'but', 'okay', '.', '\\\"']\",\n          \"['positive,\\\"In', 'particular', '-', 'the', 'parking', 'brake', 'return', 'spring', 'cable', 'assembly', 'was', 'spot', 'on', '-', 'Could', \\\"n't\\\", 'really', 'address', 'easy', 'to', 'install', 'because', 'I', 'had', 'to', 'do', 'this', 'on', 'the', 'car', ',', 'so', 'it', \\\"'s\\\", 'even', 'more', 'like', 'a', 'puzzle', 'where', 'you', 'have', 'to', 'hold', 'everything', 'in', 'place', 'while', 'you', 'add', 'that', 'last', 'component', '.', ' ', 'But', 'worked', 'very', 'well', 'for', 'my', '1999', 'Jeep', 'Wrangler', '.', '\\\"']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Filtered Tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3512,\n        \"samples\": [\n          \"['negative', ',', 'cunplio', 'el', 'objetivo', 'pue', 'sello', 'toda', 'la', 'grieta', 'quisas', 'supe', 'hacerlo']\",\n          \"['positive', ',', 'Fits', 'Elantra', 'perfectly', '!', 'Love', 'softness', 'material', 'darkness', 'black', '.']\",\n          \"['positive,\\\"First', ',', 'identical', 'sunshade', '2016', 'Forester', '.', 'nice', 'addition', 'flexible', 'case', 'sunshade', 'it.<br', '/><br', \\\"/>I've\\\", 'tried', 'sunshades', 'circular', 'things', 'unfold', ',', 'squeeze', 'window', ',', 'wrestle', 'fold', 'removed', '.', 'Personally', ',', 'found', 'time', '-', 'wasting', 'pain.<br', '/><br', '/>This', 'simply', 'folds', '.', 'Leave', 'interior', 'showing', ';', 'way', 'reflective', 'silver', 'wo', 'scratched', 'sitting', 'seat', 'driver.<br', '/><br', '/>I', 'grant', 'damaged', 'set', 'weight', '.', 'know', 'cardboard', ',', 'form', 'stiff', 'foam', ',', ',', 'believe', 'cracked', 'things', 'folded', 'up.<br', '/><br', '/>It', 'help', 'protect', 'interior', 'car', 'vinyl', 'leather', '-', 'covered', 'seats', '.', 'believe', 'helps', 'reduce', 'interior', 'heat', 'somewhat', '.', '\\\"']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS Tags\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3548,\n        \"samples\": [\n          \"[('positive,\\\"This', 'DET'), ('helmet', 'NOUN'), ('fits', 'VERB'), ('like', 'ADP'), ('it', 'PRON'), ('should', 'AUX'), (',', 'PUNCT'), ('unlike', 'ADP'), ('some', 'PRON'), ('of', 'ADP'), ('the', 'DET'), ('MAJOR', 'PROPN'), ('well', 'ADV'), ('known', 'VERB'), ('brands', 'NOUN'), ('.', 'PUNCT'), ('I', 'PRON'), ('have', 'VERB'), ('mine', 'PRON'), ('stickered', 'VERB'), ('up', 'ADP'), (',', 'PUNCT'), ('and', 'CCONJ'), ('it', 'PRON'), ('draws', 'VERB'), ('attention', 'NOUN'), ('.', 'PUNCT'), ('Would', 'AUX'), (',', 'PUNCT'), ('and', 'CCONJ'), ('will', 'AUX'), (',', 'PUNCT'), ('buy', 'VERB'), ('this', 'DET'), ('helmet', 'NOUN'), ('model', 'NOUN'), ('again', 'ADV'), ('(', 'PUNCT'), ('new', 'ADJ'), ('color', 'NOUN'), (')', 'PUNCT'), ('.', 'PUNCT'), ('The', 'DET'), ('ONLY', 'ADJ'), ('thing', 'NOUN'), ('I', 'PRON'), ('do', 'AUX'), (\\\"n't\\\", 'PART'), ('like', 'VERB'), (',', 'PUNCT'), ('the', 'DET'), ('strap', 'NOUN'), ('fitting', 'VERB'), ('arrangement', 'NOUN'), ('.', 'PUNCT'), ('\\\"', 'PUNCT')]\",\n          \"[('negative,\\\"Not', 'ADV'), ('what', 'PRON'), ('I', 'PRON'), ('expected', 'VERB'), (',', 'PUNCT'), ('but', 'CCONJ'), ('okay', 'INTJ'), ('.', 'PUNCT'), ('\\\"', 'PUNCT')]\",\n          \"[('positive,\\\"In', 'ADJ'), ('particular', 'ADJ'), ('-', 'PUNCT'), ('the', 'DET'), ('parking', 'NOUN'), ('brake', 'NOUN'), ('return', 'NOUN'), ('spring', 'NOUN'), ('cable', 'NOUN'), ('assembly', 'NOUN'), ('was', 'AUX'), ('spot', 'NOUN'), ('on', 'ADV'), ('-', 'PUNCT'), ('Could', 'AUX'), (\\\"n't\\\", 'PART'), ('really', 'ADV'), ('address', 'VERB'), ('easy', 'ADJ'), ('to', 'PART'), ('install', 'VERB'), ('because', 'SCONJ'), ('I', 'PRON'), ('had', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('this', 'PRON'), ('on', 'ADP'), ('the', 'DET'), ('car', 'NOUN'), (',', 'PUNCT'), ('so', 'SCONJ'), ('it', 'PRON'), (\\\"'s\\\", 'AUX'), ('even', 'ADV'), ('more', 'ADV'), ('like', 'ADP'), ('a', 'DET'), ('puzzle', 'NOUN'), ('where', 'SCONJ'), ('you', 'PRON'), ('have', 'VERB'), ('to', 'PART'), ('hold', 'VERB'), ('everything', 'PRON'), ('in', 'ADP'), ('place', 'NOUN'), ('while', 'SCONJ'), ('you', 'PRON'), ('add', 'VERB'), ('that', 'SCONJ'), ('last', 'ADJ'), ('component', 'NOUN'), ('.', 'PUNCT'), (' ', 'SPACE'), ('But', 'CCONJ'), ('worked', 'VERB'), ('very', 'ADV'), ('well', 'ADV'), ('for', 'ADP'), ('my', 'PRON'), ('1999', 'NUM'), ('Jeep', 'PROPN'), ('Wrangler', 'PROPN'), ('.', 'PUNCT'), ('\\\"', 'PUNCT')]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Named Entities\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1568,\n        \"samples\": [\n          \"[('first', 'ORDINAL'), ('three', 'CARDINAL'), ('R-12', 'PRODUCT'), ('U.S.', 'GPE'), ('R-12', 'PRODUCT'), ('around 1993', 'DATE'), ('U.S.', 'GPE'), ('R-134A.', 'PERSON'), ('two', 'CARDINAL'), ('three', 'CARDINAL'), ('first', 'ORDINAL'), ('second', 'ORDINAL'), ('two', 'CARDINAL'), ('6015', 'CARDINAL'), ('6014.<br', 'CARDINAL'), ('third', 'ORDINAL'), ('AC', 'ORG'), ('5', 'CARDINAL')]\",\n          \"[('HEPA', 'ORG')]\",\n          \"[('Glad', 'PERSON')]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method Unsupervised Start\n",
        "\n",
        "In this section you will write all details of your Method 1.\n",
        "\n",
        "You will have to enter multiple `code` and `text` cell.\n",
        "\n",
        "Your code should follow the standard ML pipeline\n",
        "\n",
        "\n",
        "*   Data reading\n",
        "*   Data clearning, if any\n",
        "*   Convert data to vector/tokenization/vectorization\n",
        "*   Model Declaration/Initialization/building\n",
        "*   Training and validation of the model using training and validation dataset\n",
        "*   Save the trained model\n",
        "*   Load and Test the model on testing set\n",
        "*   Save the output of the model\n",
        "\n",
        "\n",
        "You could add any other step(s) based on your method's requirement.\n",
        "\n",
        "After finishing the above, you need to usd splited data as defined in the assignment and then do the same for all 4 sets. Your code should not be copy-pasted 4 time, make use of `function`.\n"
      ],
      "metadata": {
        "id": "47ywe8jGSKhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code(s)"
      ],
      "metadata": {
        "id": "6W5H-VeKi7-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Unsupervised Method Code\n",
        "Your test code should be a stand alone code that must take `train_file`, `val_file`,  and `model_dir` as input. You could have other things as also input, but these three are must. You would load both files, and train using the `train_file` and validating using the `val_file`. You will `print` / `display`/ `plot` all performance metrics, loss(if available) and save the output model in the `model_dir`.\n",
        "\n",
        "Note that at the testing time, you need to use the same pre-processing and model. So, it would be good that you make those as seperate function/pipeline whichever it the best suited for your method. Don't copy-paste same code twice, make it a fucntion/class whichever is best."
      ],
      "metadata": {
        "id": "1sA3OWlVbnoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code(s)"
      ],
      "metadata": {
        "id": "fkJ5LiXoipcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Method Unsupervised Code\n",
        "Your test code should be a stand alone code that must take `test_file`, `model_file` and `output_dir` as input. You could have other things as also input, but these three are must. You would load both files, and generate output based on inputs. Then you will `print` / `display`/ `plot` all performance metrics, and save the output file in the `output_dir`  "
      ],
      "metadata": {
        "id": "qyJ_xv12Uy9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code(s)"
      ],
      "metadata": {
        "id": "UZs5nzA4ivqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method Unsupervised End\n"
      ],
      "metadata": {
        "id": "ue3xIDFGSXNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method Discriminative Start\n",
        "\n",
        "In this section you will write all details of your Method 2.\n",
        "\n",
        "You will have to enter multiple `code` and `text` cell.\n",
        "\n",
        "Your code should follow the standard ML pipeline\n",
        "\n",
        "\n",
        "*   Data reading\n",
        "*   Data clearning, if any\n",
        "*   Convert data to vector/tokenization/vectorization\n",
        "*   Model Declaration/Initialization/building\n",
        "*   Training and validation of the model using training and validation dataset\n",
        "*   Save the trained model\n",
        "*   Load and Test the model on testing set\n",
        "*   Save the output of the model\n",
        "\n",
        "You could add any other step(s) based on your method's requirement.\n",
        "\n",
        "After finishing the above, you need to usd splited data as defined in the assignment and then do the same for all 4 sets. Your code should not be copy-pasted 4 time, make use of `function`.\n"
      ],
      "metadata": {
        "id": "o5jNIHneSfzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code(s)"
      ],
      "metadata": {
        "id": "KZzeItA7iyIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Method Discriminative Code\n",
        "Your test code should be a stand alone code that must take `train_file`, `val_file`,  and `model_dir` as input. You could have other things as also input, but these three are must. You would load both files, and train using the `train_file` and validating using the `val_file`. You will `print` / `display`/ `plot` all performance metrics, loss(if available) and save the output model in the `model_dir`.\n",
        "\n",
        "Note that at the testing time, you need to use the same pre-processing and model. So, it would be good that you make those as seperate function/pipeline whichever it the best suited for your method. Don't copy-paste same code twice, make it a fucntion/class whichever is best."
      ],
      "metadata": {
        "id": "zAkC0CWAc1BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code(s)"
      ],
      "metadata": {
        "id": "UAfRiq7cixij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Method Discriminative Code\n",
        "Your test code should be a stand alone code that must take `test_file`, `model_file` and `output_dir` as input. You could have other things as also input, but these three are must. You would load both files, and generate output based on inputs. Then you will `print` / `display`/ `plot` all performance metrics, and save the output file in the `output_dir`  "
      ],
      "metadata": {
        "id": "LVi2vGeZc5Fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code(s)"
      ],
      "metadata": {
        "id": "VSTzjETEiy_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminative Method  End\n"
      ],
      "metadata": {
        "id": "4gNwyxXNSmVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other Method/model Start"
      ],
      "metadata": {
        "id": "rmaJfJkVwSDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Code(s)"
      ],
      "metadata": {
        "id": "V1BL_w7Ai0pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Other Method/model End"
      ],
      "metadata": {
        "id": "7yMswIeAwYIf"
      }
    }
  ]
}